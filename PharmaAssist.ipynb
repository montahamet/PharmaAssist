{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install langchain_chroma langchain_groq langchain_core langchain_community langchain_text_splitters pypdf gradio sentence-transformers"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters.sentence_transformers import SentenceTransformersTokenTextSplitter\n",
    "from langchain_chroma import Chroma"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create directory for persistent DB\n",
    "os.makedirs('pharma_db', exist_ok=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize embedding model and Chroma vector DB\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')\n",
    "db = Chroma(collection_name='pharma_database', embedding_function=embedding_model, persist_directory='pharma_db')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a highly knowledgeable assistant specializing in pharmaceutical sciences.\n",
    "Answer the question based only on the following context:\n",
    "{context}\n\n",
    "Answer the question based on the above context:\n",
    "{question}\n\n",
    "Use the provided context to answer the user's question accurately and concisely.\n",
    "Don't justify your answers.\n",
    "Don't give information not mentioned in the CONTEXT INFORMATION.\n",
    "Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "output_parser = StrOutputParser()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Helper function to format retrieved documents\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Function to process uploaded PDF files\n",
    "def process_documents(file_paths):\n",
    "    for file_path in file_paths:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        data = loader.load()\n",
    "\n",
    "        doc_metadata = [doc.metadata for doc in data]\n",
    "        doc_content = [doc.page_content for doc in data]\n",
    "\n",
    "        text_splitter = SentenceTransformersTokenTextSplitter(\n",
    "            model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "            chunk_size=100,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        chunks = text_splitter.create_documents(doc_content, doc_metadata)\n",
    "        db.add_documents(chunks)\n",
    "\n",
    "    return '✅ Documents processed and added to database.'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Function to Query using RAG\n",
    "def run_query(query, groq_api_key):\n",
    "    retriever = db.as_retriever(search_type='similarity', search_kwargs={'k': 5})\n",
    "    llm = ChatGroq(model='llama-3.3-70b-versatile', api_key=groq_api_key, temperature=1)\n",
    "\n",
    "    rag_chain = (\n",
    "        {'context': retriever | format_docs, 'question': RunnablePassthrough()}\n",
    "        | prompt_template\n",
    "        | llm\n",
    "        | output_parser\n",
    "    )\n",
    "\n",
    "    return rag_chain.invoke(query)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example Usage (optional, CLI testing)\n",
    "# pdf_paths = ['sample1.pdf', 'sample2.pdf']\n",
    "# process_documents(pdf_paths)\n",
    "\n",
    "# groq_api_key = 'YOUR_GROQ_API_KEY'\n",
    "# query = 'What are the AI applications in drug discovery?'\n",
    "# print(run_query(query, groq_api_key))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Gradio Interface\n",
    "def pharma_query_interface(query, groq_api_key, files):\n",
    "    if files:\n",
    "        process_documents(files)\n",
    "    if not query or not groq_api_key:\n",
    "        return '⚠️ Please enter a query and your GROQ API key.'\n",
    "    return run_query(query, groq_api_key)\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=pharma_query_interface,\n",
    "    inputs=[\n",
    "        gr.Textbox(label='Pharmaceutical Question', placeholder='e.g., What are the AI applications in drug discovery?'),\n",
    "        gr.Textbox(label='Groq API Key', type='password'),\n",
    "        gr.File(label='Upload PDF documents (optional)', file_types=['.pdf'], file_count='multiple')\n",
    "    ],\n",
    "    outputs=gr.Textbox(label='RAG Answer', lines=10),\n",
    "    title='PharmaAssist - RAG for Pharmaceutical Research',\n",
    "    description='Upload pharmaceutical research PDFs and ask questions using Groq\\'s LLaMA3 and HuggingFace Embeddings.'\n",
    ")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    iface.launch()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
